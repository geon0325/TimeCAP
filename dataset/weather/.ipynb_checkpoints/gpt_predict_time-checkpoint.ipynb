{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d0aa91f-ca94-4478-bf54-9f0c96d7da77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pickle as pkl\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ca69ebf-dd42-4fe4-a97a-2f4f81b3b87a",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "894a4b0d-84a2-4819-bd23-b38462ae04b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "city = 'ny'\n",
    "\n",
    "city_full_name = {\n",
    "    'ny': 'New York City',\n",
    "    'hs': 'Houston',\n",
    "    'sf': 'San Francisco'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "182b5ba4-69bb-4fc4-bf22-677bd4b69d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('indices.pkl', 'rb') as f:\n",
    "    indices = pkl.load(f)\n",
    "    \n",
    "with open('dates.pkl', 'rb') as f:\n",
    "    dates = pkl.load(f)\n",
    "    \n",
    "with open(f'time_series_{city}.pkl', 'rb') as f:\n",
    "    data = pkl.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "830042c6-e1ca-4db9-90b8-b63971348534",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_size = data.shape[0]\n",
    "window_size = 24\n",
    "print(data_size, window_size, len(indices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "467934d5-c092-4bbc-b559-bad0e93374ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_size = len(indices)\n",
    "\n",
    "num_train = int(data_size * 0.6)\n",
    "num_test = int(data_size * 0.2)\n",
    "num_vali = data_size - num_train - num_test\n",
    "\n",
    "seq_len_day = 1\n",
    "\n",
    "idx_train = np.arange(num_train - seq_len_day)\n",
    "idx_valid = np.arange(num_train - seq_len_day, num_train + num_vali - seq_len_day)\n",
    "idx_test = np.arange(num_train + num_vali - seq_len_day, num_train + num_vali + num_test - seq_len_day)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a816c8de-74a8-4332-8c13-86ff538123a0",
   "metadata": {},
   "source": [
    "## Prompt GPT 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42913fe5-c1a8-4427-89ad-a6f30ac3a6b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "API_KEY = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddfd6cc3-e6c9-438b-ae45-d694b09d92e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = f\"Your job is to act as a professional weather forecaster. You will be given a time-series data of the weather from the past 24 hours. Based on this information, your task is to predict whether it will rain in the next 24 hours.\"\n",
    "print(system_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2639b368-c3e1-42c6-a434-994a2caacb69",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(api_key=API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8092ebc2-a343-4018-a512-2703a602e8a4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for _i in idx_test:\n",
    "    i = indices[_i]\n",
    "    \n",
    "    data_window = data[i:i+window_size]\n",
    "    \n",
    "    humidity = '|'.join([f\"{x:.2f}\" for x in data_window[:,0]])\n",
    "    pressure = '|'.join([f\"{x:.2f}\" for x in data_window[:,1]])\n",
    "    temperature = '|'.join([f\"{x:.2f}\" for x in data_window[:,2]])\n",
    "    wind_speed = '|'.join([f\"{x:.2f}\" for x in data_window[:,3]])\n",
    "    wind_direction = '|'.join([f\"{x:.2f}\" for x in data_window[:,4]])\n",
    "    \n",
    "    user_prompt = f\"Your task is to predict whether it will rain or not in {city_full_name[city]} in the next {window_size} hours. \"\n",
    "    user_prompt += f\"Review the time-series data provided for the last {window_size} hours. \"\n",
    "    user_prompt += f\"Each time-series consists of hourly values separated by a \\'|\\' token for the following indicators:\\n\\n\"\n",
    "    user_prompt += f\"- Temperature (Kelvin): {temperature}\\n- Humidity (%): {humidity}\\n- Air Pressure (hPa): {pressure}\\n- Wind Speed (m/s): {wind_speed}\\n- Wind Direction (degrees): {wind_direction}\\n\\n\"\n",
    "    user_prompt += f\"Based on this information, respond with either \\'rain\\' or \\'not rain\\'. Do not provide any other details. \"\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4-1106-preview\",\n",
    "        messages=[\n",
    "        {\n",
    "          \"role\": \"system\",\n",
    "          \"content\": system_prompt\n",
    "        },\n",
    "        {\n",
    "          \"role\": \"user\",\n",
    "          \"content\": user_prompt\n",
    "        }\n",
    "        ],\n",
    "        temperature=0.7,\n",
    "        max_tokens=2048,\n",
    "        top_p=1\n",
    "    )\n",
    "\n",
    "    text = response.choices[0].message.content\n",
    "\n",
    "    with open(f'gpt_predict/{city}_{i}.txt', 'w') as f:\n",
    "        f.write(text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
