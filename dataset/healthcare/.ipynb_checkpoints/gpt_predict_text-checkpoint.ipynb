{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d0aa91f-ca94-4478-bf54-9f0c96d7da77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pickle as pkl\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d242311-be57-401a-9c7a-2cdd4b09fb27",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d620d1-0c25-4e3d-b483-f23f3f396e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "indicator = 'positive'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f875b9fe-b65f-4f50-80d6-a8eabf041c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'time_series_{indicator}.pkl', 'rb') as f:\n",
    "    data = pkl.load(f)\n",
    "\n",
    "with open(f'indices_{indicator}.pkl', 'rb') as f:\n",
    "    indices = pkl.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07d01377-8869-4e66-b189-e945d9112b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = {}\n",
    "for i in indices:\n",
    "    with open(os.path.join('gpt_summary', f'{i}_{indicator}.txt'), 'r') as f:\n",
    "        text = f.read()\n",
    "        texts[i] = text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3abc7227-1ea6-4535-bd6d-f2c819faf547",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_size = data.shape[0]\n",
    "window_size = 20\n",
    "print(data_size, data.shape, window_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "467934d5-c092-4bbc-b559-bad0e93374ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_size = len(indices)\n",
    "\n",
    "num_train = int(data_size * 0.6)\n",
    "num_test = int(data_size * 0.2)\n",
    "num_vali = data_size - num_train - num_test\n",
    "\n",
    "idx_train = np.arange(num_train)\n",
    "idx_valid = np.arange(num_train, num_train + num_vali)\n",
    "idx_test = np.arange(num_train + num_vali, num_train + num_vali + num_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c47cfd93-9e6c-4346-9fda-3ebb401b0a1b",
   "metadata": {},
   "source": [
    "## Prompt GPT 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35e409e1-4fd5-482b-b97d-c75d6a0a0532",
   "metadata": {},
   "outputs": [],
   "source": [
    "API_KEY = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddfd6cc3-e6c9-438b-ae45-d694b09d92e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "if indicator == 'positive':\n",
    "    system_prompt = f\"Your job is to act as a professional healthcare forecaster. You will be given a healthcare summary of the past 20 weeks. Based on this information, your task is to predict whether the percentage of respiratory specimens testing positive for influenza will exceed the average threshold in the comming week.\"\n",
    "elif indicator == 'mortality':\n",
    "    system_prompt = f\"Your job is to act as a professional healthcare forecaster. You will be given a healthcare summary of the past 20 weeks. Based on this information, your task is to predict whether the ratio of mortality from Influenza or Pneumonia to the total number of death will exceed its average in the comming week.\"\n",
    "\n",
    "print(system_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2639b368-c3e1-42c6-a434-994a2caacb69",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(api_key=API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8092ebc2-a343-4018-a512-2703a602e8a4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for _i in idx_test:\n",
    "    i = indices[_i]\n",
    "    \n",
    "    today = data[i][0]\n",
    "\n",
    "    if indicator == 'posiive':\n",
    "        user_prompt = f\"Your task is to predict whether the percentage of respiratory specimens testing positive for influenza will:\\n\"\n",
    "        user_prompt += \"(1) Exceed its average of 6.26%\\n(2) Not exceed its average of 6.26%\\n\"\n",
    "        user_prompt += \"in the coming week. \"\n",
    "        user_prompt += f\"The healthcare situation of the last {window_size} weeks is summarized as follows:\\n\\n\"\n",
    "        user_prompt += f\"{texts[i]}\\n\\n\"\n",
    "        user_prompt += f\"Analyze this summary and predict whether the percentage of respiratory specimens testing positive for influenza will exceed the average of 6.26% or not. \"\n",
    "        user_prompt += \"Respond with either \\'exceed\\' or \\'not exceed\\'. Do not provide any other details.\"\n",
    "\n",
    "    elif indicator == 'mortality':\n",
    "        user_prompt = f\"Your task is to predict whether the ratio of mortality from Influenza or Pneumonia to the total number of death will:\\n\"\n",
    "        user_prompt += \"(1) Exceed its average of 7.84%\\n(2) Not exceed its average of 7.84%\\n\"\n",
    "        user_prompt += \"in the coming week. \"\n",
    "        user_prompt += f\"The healthcare situation of the last {window_size} weeks is summarized as follows:\\n\\n\"\n",
    "        user_prompt += f\"{texts[i]}\\n\\n\"\n",
    "        user_prompt += f\"Analyze this summary and predict whether the ratio of mortality from Influenza or Pneumonia to the total number of death will exceed the average of 7.84% or not. \"\n",
    "        user_prompt += \"Respond with either \\'exceed\\' or \\'not exceed\\'. Do not provide any other details.\"\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4-1106-preview\",\n",
    "        messages=[\n",
    "        {\n",
    "          \"role\": \"system\",\n",
    "          \"content\": system_prompt\n",
    "        },\n",
    "        {\n",
    "          \"role\": \"user\",\n",
    "          \"content\": user_prompt\n",
    "        }\n",
    "        ],\n",
    "        temperature=0.7,\n",
    "        max_tokens=2048,\n",
    "        top_p=1\n",
    "    )\n",
    "\n",
    "    text = response.choices[0].message.content\n",
    "\n",
    "    with open(f'gpt_predict_text/{i}_{indicator}.txt', 'w') as f:\n",
    "        f.write(text)\n",
    "    #break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ebba8f3-d2dd-4831-9d0b-cc75aae73683",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
