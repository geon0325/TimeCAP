{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d0aa91f-ca94-4478-bf54-9f0c96d7da77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pickle as pkl\n",
    "from openai import OpenAI\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f1c93e7-8a8f-4f33-93c4-7d14b9708c52",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b1a6488-926c-4a89-b8a6-2fbd8280f63d",
   "metadata": {},
   "outputs": [],
   "source": [
    "indicator = 'positive'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "182b5ba4-69bb-4fc4-bf22-677bd4b69d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'time_series_{indicator}.pkl', 'rb') as f:\n",
    "    data = pkl.load(f)\n",
    "    \n",
    "with open(f'indices_{indicator}.pkl', 'rb') as f:\n",
    "    indices = pkl.load(f)\n",
    "    \n",
    "with open(f'labels_{indicator}.pkl', 'rb') as f:\n",
    "    labels = pkl.load(f)\n",
    "    \n",
    "texts = {}\n",
    "for i in indices:\n",
    "    with open(os.path.join('gpt_summary', f'{i}_{indicator}.txt'), 'r') as f:\n",
    "        text = f.read()\n",
    "        texts[i] = text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca6b7147-a9ef-4217-a35c-6e67a3dd4425",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_size = data.shape[0]\n",
    "window_size = 20\n",
    "print(data_size, data.shape, window_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c389ebb-145c-420e-b29a-6e48ed5265d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_size = len(indices)\n",
    "\n",
    "num_train = int(data_size * 0.6)\n",
    "num_test = int(data_size * 0.2)\n",
    "num_vali = data_size - num_train - num_test\n",
    "\n",
    "idx_train = np.arange(num_train)\n",
    "idx_valid = np.arange(num_train, num_train + num_vali)\n",
    "idx_test = np.arange(num_train + num_vali, num_train + num_vali + num_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87d81d43-aed8-485f-8896-c38ccc03cfdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'../../encoder/embeddings/healthcare_{indicator}.pkl', 'rb') as f:\n",
    "    embs = pkl.load(f)\n",
    "\n",
    "text_emb = {}\n",
    "for _i, i in enumerate(indices):\n",
    "    text_emb[i] = embs[_i]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ff249fc-f72b-48d5-b130-246eeb1f84b7",
   "metadata": {},
   "source": [
    "## Prompt GPT 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "550631f0-e956-419e-acc7-9468755f8ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cos(a, b):\n",
    "    cos_sim = np.dot(a, b)/(norm(a)*norm(b))\n",
    "    return cos_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e2faffe-061b-4c1e-ba37-663d457b9a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of in-context examples\n",
    "k = 5\n",
    "\n",
    "# OPEN AI API Key\n",
    "API_KEY = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddfd6cc3-e6c9-438b-ae45-d694b09d92e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "if indicator == 'positive':\n",
    "    system_prompt = f\"Your job is to act as a professional healthcare forecaster. You will be given a healthcare summary of the past 20 weeks. Based on this information, your task is to predict whether the percentage of respiratory specimens testing positive for influenza will exceed the average threshold in the comming week.\"\n",
    "elif indicator == 'mortality':\n",
    "    system_prompt = f\"Your job is to act as a professional healthcare forecaster. You will be given a healthcare summary of the past 20 weeks. Based on this information, your task is to predict whether the ratio of mortality from Influenza or Pneumonia to the total number of death will exceed the average threshold in the comming week.\"\n",
    "\n",
    "print(system_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9863734-a628-40fb-844b-0b37494645f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(api_key=API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8092ebc2-a343-4018-a512-2703a602e8a4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "random.seed(2024)\n",
    "\n",
    "for _i in idx_test:\n",
    "    i = indices[_i]\n",
    "    \n",
    "    if indicator == 'positive':\n",
    "        user_prompt = f\"Your task is to predict whether the percentage of respiratory specimens testing positive for influenza will:\\n\"\n",
    "        user_prompt += \"(1) Exceed its average of 6.26%\\n(2) Not exceed its average of 6.26%\\n\"\n",
    "        user_prompt += \"in the coming week. \"\n",
    "        user_prompt += f\"First, review the following {k} examples of healthcare summaries and their outcomes so that you can refer to when making predictions.\\n\\n\"\n",
    "        \n",
    "    elif indicator == 'mortality':\n",
    "        user_prompt = f\"Your task is to predict whether the ratio of mortality from Influenza or Pneumonia to the total number of death will:\\n\"\n",
    "        user_prompt += \"(1) Exceed its average of 7.84%\\n(2) Not exceed its average of 7.84%\\n\"\n",
    "        user_prompt += \"in the coming week. \"\n",
    "        user_prompt += f\"First, review the following {k} examples of healthcare summaries and their outcomes so that you can refer to when making predictions.\\n\\n\"\n",
    "\n",
    "    sim = [-cos(text_emb[i], text_emb[indices[ii]]) for ii in idx_train]\n",
    "    _j_list = np.argsort(sim)\n",
    "    \n",
    "    for _k in range(k):\n",
    "        _j = _j_list[_k]\n",
    "        j = indices[_j]\n",
    "        \n",
    "        _text = texts[j].replace('\\n\\n', ' ')\n",
    "        user_prompt += f\"Summary #{_k+1}: {_text}\"\n",
    "        \n",
    "        if labels[_j] == 0:\n",
    "            if indicator == 'positive':\n",
    "                user_prompt += f\"\\nOutcome #{_k+1}: Did not exceed 6.26%\\n\\n\"\n",
    "            elif indicator == 'mortality':\n",
    "                user_prompt += f\"\\nOutcome #{_k+1}: Did not exceed 7.84%\\n\\n\"\n",
    "        elif labels[_j] == 1:\n",
    "            if indicator == 'positive':\n",
    "                user_prompt += f\"\\nOutcome #{_k+1}: Exceeded 6.26%\\n\\n\"\n",
    "            elif inidicator == 'mortality':\n",
    "                user_prompt += f\"\\nOutcome #{_k+1}: Exceeded 7.84%\\n\\n\"\n",
    "    \n",
    "    user_prompt += f\"The healthcare situation of the last {window_size} weeks is summarized as follows:\\n\\n\"\n",
    "    \n",
    "    _text = texts[i].replace('\\n\\n', ' ')\n",
    "    user_prompt += f\"Summary: {_text}\\n\"\n",
    "    user_prompt += f\"Outcome:\\n\\n\"\n",
    "    \n",
    "    user_prompt += f\"Refer to the provided examples and predict the outcome of the current healthcare summary. \"\n",
    "    user_prompt += \"Respond with either \\'exceed\\' or \\'not exceed\\'. \"\n",
    "    user_prompt += \"Response should not include other terms.\"\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4-1106-preview\",\n",
    "        messages=[\n",
    "        {\n",
    "          \"role\": \"system\",\n",
    "          \"content\": system_prompt\n",
    "        },\n",
    "        {\n",
    "          \"role\": \"user\",\n",
    "          \"content\": user_prompt\n",
    "        }\n",
    "        ],\n",
    "        temperature=0.7,\n",
    "        max_tokens=2048,\n",
    "        top_p=1\n",
    "    )\n",
    "\n",
    "    text = response.choices[0].message.content\n",
    "    \n",
    "    with open(f'gpt_predict_in-context/k{k}_{i}_{indicator}_ref_int.txt', 'w') as f:\n",
    "        f.write(f'{text}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
