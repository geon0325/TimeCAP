{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d0aa91f-ca94-4478-bf54-9f0c96d7da77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pickle as pkl\n",
    "from openai import OpenAI\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1201eb1c-275a-4f2e-b68b-bd039dbf4521",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b1a6488-926c-4a89-b8a6-2fbd8280f63d",
   "metadata": {},
   "outputs": [],
   "source": [
    "indicator = 'sp500'\n",
    "\n",
    "indicator2name = {\n",
    "    'sp500': 'S&P 500',\n",
    "    'nikkei': 'Nikkei 225'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "182b5ba4-69bb-4fc4-bf22-677bd4b69d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('indices.pkl', 'rb') as f:\n",
    "    indices = pkl.load(f)\n",
    "\n",
    "with open(f'time_series.pkl', 'rb') as f:\n",
    "    data = pkl.load(f)\n",
    "    \n",
    "with open(os.path.join(f'labels_{indicator}.pkl'), 'rb') as f:\n",
    "    labels = pkl.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a5f8565-a344-4bcc-8cb7-8be9b328f268",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = {}\n",
    "for i in indices:\n",
    "    with open(os.path.join('gpt_summary', f'{i}.txt'), 'r') as f:\n",
    "        text = f.read()\n",
    "        texts[i] = text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b3ad184-5fee-4629-a16e-ecb065a68985",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_size = data.shape[0]\n",
    "window_size = 20\n",
    "print(data_size, window_size, len(indices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e9fb860-584c-468d-98b3-b8eec0efe042",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_size = len(indices)\n",
    "\n",
    "num_train = int(data_size * 0.6)\n",
    "num_test = int(data_size * 0.2)\n",
    "num_vali = data_size - num_train - num_test\n",
    "\n",
    "idx_train = np.arange(num_train)\n",
    "idx_valid = np.arange(num_train, num_train + num_vali)\n",
    "idx_test = np.arange(num_train + num_vali, num_train + num_vali + num_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87d81d43-aed8-485f-8896-c38ccc03cfdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'../../encoder/embeddings/finance_{indicator}.pkl', 'rb') as f:\n",
    "    embs = pkl.load(f)\n",
    "    \n",
    "text_emb = {}\n",
    "for _i, i in enumerate(indices[:-1]):\n",
    "    text_emb[i] = embs[_i]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be6711e6-90b9-4ef7-8c4c-65ef7efb0454",
   "metadata": {},
   "source": [
    "## Prompt GPT 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "550631f0-e956-419e-acc7-9468755f8ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cos(a, b):\n",
    "    cos_sim = np.dot(a, b)/(norm(a)*norm(b))\n",
    "    return cos_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "049db32d-966a-487d-8f08-60f9df3ce5a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of in-context examples\n",
    "k = 5\n",
    "\n",
    "# OPEN AI API Key\n",
    "API_KEY = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddfd6cc3-e6c9-438b-ae45-d694b09d92e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = f\"Your job is to act as a professional financial forecaster. You will be given a summary of the financial situation of the past 20 market days. Based on this information, your task is to predict whether the {indicator2name[indicator]} price will decrease by more than 1%, increase by more than 1%, or change minimally in the next market day.\"\n",
    "print(system_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8092ebc2-a343-4018-a512-2703a602e8a4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "random.seed(2024)\n",
    "\n",
    "for _i in idx_test:\n",
    "    i = indices[_i]\n",
    "    \n",
    "    today = data[i][0]\n",
    "    print(today)\n",
    "    \n",
    "    user_prompt = f\"Your task is to predict whether the {indicator2name[indicator]} price will:\\n\"\n",
    "    user_prompt += f\"(1) Decrease: decrease by more than 1%\\n(2) Increase: increase by more than 1%\\n(3) Neutral: change minimally, between -1% and 1%\\nin the next market day. \"\n",
    "    user_prompt += f\"First, review the following {k} examples of financial summaries and {indicator2name[indicator]} outcomes so that you can refer to when making predictions.\\n\\n\"\n",
    "    \n",
    "    sim = [-cos(text_emb[i], text_emb[indices[ii]]) for ii in idx_train]\n",
    "    _j_list = np.argsort(sim)\n",
    "    \n",
    "    for _k in range(k):\n",
    "        _j = _j_list[_k]\n",
    "        j = indices[_j]\n",
    "        \n",
    "        _text = texts[j].replace('\\n\\n', ' ')\n",
    "        user_prompt += f\"Summary #{_k+1}: {_text}\"\n",
    "        \n",
    "        if labels[_j] == 0:\n",
    "            user_prompt += f\"\\nOutcome #{_k+1}: Decreased\\n\\n\"\n",
    "        elif labels[_j] == 1:\n",
    "            user_prompt += f\"\\nOutcome #{_k+1}: Neutral\\n\\n\"\n",
    "        else:\n",
    "            user_prompt += f\"\\nOutcome #{_k+1}: Increased\\n\\n\"\n",
    "    \n",
    "    user_prompt += f\"The financial situation of the last {window_size} market days is summarized as follows:\\n\\n\"\n",
    "    \n",
    "    _text = texts[i].replace('\\n\\n', ' ')\n",
    "    user_prompt += f\"Summary: {_text}\\n\"\n",
    "    user_prompt += f\"Outcome:\\n\\n\"\n",
    "    \n",
    "    user_prompt += f\"Refer to the provided examples and predict the outcome of the current financial summary. \"\n",
    "    user_prompt += \"Respond your prediction with either 'decrease', 'increase' or 'neutral'. \"\n",
    "    user_prompt += \"Response should not include other terms.\"\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4-1106-preview\",\n",
    "        messages=[\n",
    "        {\n",
    "          \"role\": \"system\",\n",
    "          \"content\": system_prompt\n",
    "        },\n",
    "        {\n",
    "          \"role\": \"user\",\n",
    "          \"content\": user_prompt\n",
    "        }\n",
    "        ],\n",
    "        temperature=0.7,\n",
    "        max_tokens=2048,\n",
    "        top_p=1\n",
    "    )\n",
    "\n",
    "    text = response.choices[0].message.content\n",
    "    \n",
    "    with open(f'gpt_predict_in-context/k{k}_{i}_{indicator}_ref.txt', 'w') as f:\n",
    "        f.write(f'{text}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
