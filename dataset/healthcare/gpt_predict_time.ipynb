{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d0aa91f-ca94-4478-bf54-9f0c96d7da77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pickle as pkl\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00fe1013-465b-477f-9200-f08de0d59eef",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d4a282c-d11e-4436-b52f-c1221ef70a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "indicator = 'positive'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "182b5ba4-69bb-4fc4-bf22-677bd4b69d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'indices_{indicator}.pkl', 'rb') as f:\n",
    "    indices = pkl.load(f)\n",
    "    \n",
    "with open(f'time_series_{indicator}.pkl', 'rb') as f:\n",
    "    data = pkl.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "830042c6-e1ca-4db9-90b8-b63971348534",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_size = data.shape[0]\n",
    "window_size = 20\n",
    "print(data_size, window_size, len(indices), data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "467934d5-c092-4bbc-b559-bad0e93374ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_size = len(indices)\n",
    "\n",
    "num_train = int(data_size * 0.6)\n",
    "num_test = int(data_size * 0.2)\n",
    "num_vali = data_size - num_train - num_test\n",
    "\n",
    "idx_train = np.arange(num_train)\n",
    "idx_valid = np.arange(num_train, num_train + num_vali)\n",
    "idx_test = np.arange(num_train + num_vali, num_train + num_vali + num_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b070a61a-7e4e-4ad3-a9bc-2078fdd3fcac",
   "metadata": {},
   "source": [
    "## Prompt GPT 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ef0656c-2dbb-4254-91bc-6886ea26ae70",
   "metadata": {},
   "outputs": [],
   "source": [
    "API_KEY = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddfd6cc3-e6c9-438b-ae45-d694b09d92e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "if indicator == 'mortality':\n",
    "    system_prompt = f\"Your job is to act as a professional healthcare forecaster. You will be given a time-series data from the past 20 weeks. Based on this information, your task is to predict whether the ratio of mortality from Influenza or Pneumonia to the total number of death will exceed its average in the comming week.\"\n",
    "elif indicator == 'positive':\n",
    "    system_prompt = f\"Your job is to act as a professional healthcare forecaster. You will be given a time-series data from the past 20 weeks. Based on this information, your task is to predict whether the percentage of respiratory specimens testing positive for influenza will exceed its average in the comming week.\"\n",
    "print(system_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2639b368-c3e1-42c6-a434-994a2caacb69",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(api_key=API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8092ebc2-a343-4018-a512-2703a602e8a4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for _i in idx_test:\n",
    "    i = indices[_i]\n",
    "    \n",
    "    data_window = data[i:i+window_size]    \n",
    "    \n",
    "    if indicator == 'positive':\n",
    "        total_specimens = '|'.join([x for x in data_window[:,1]])\n",
    "        total_a = '|'.join([x for x in data_window[:,2]])\n",
    "        total_b = '|'.join([x for x in data_window[:,3]])\n",
    "        pos_rate = '|'.join([str(f'{float(x):.2f}') for x in data_window[:,4]])\n",
    "        a_rate = '|'.join([str(f'{float(x):.2f}') for x in data_window[:,5]])\n",
    "        b_rate = '|'.join([str(f'{float(x):.2f}') for x in data_window[:,6]])\n",
    "    \n",
    "    elif indicator == 'mortality':\n",
    "        inf_death = '|'.join([x for x in data_window[:,1]])\n",
    "        pneum_death = '|'.join([x for x in data_window[:,2]])\n",
    "        total_death = '|'.join([x for x in data_window[:,3]])\n",
    "        ratio = '|'.join([str(f'{float(x):.2f}') for x in data_window[:,4]])\n",
    "    \n",
    "    if indicator == 'positive':\n",
    "        user_prompt = f\"Your task is to predict whether the percentage of respiratory specimens testing positive for influenza will:\\n\"\n",
    "        user_prompt += \"(1) Exceed its average of 6.26%\\n(2) Not exceed its average of 6.26%\\n\"\n",
    "        user_prompt += \"in the coming week. \"\n",
    "        user_prompt += f\"Review the time-series data provided for the last {window_size} weeks. \"\n",
    "        user_prompt += f\"Each time-series consists of weekly values separated by a \\'|\\' token for the following indicators:\\n\"\n",
    "        user_prompt += f\"- Number of specimens tested: {total_specimens}\\n\"\n",
    "        user_prompt += f\"- Number of positive specimens for Influenza A: {total_a}\\n\"\n",
    "        user_prompt += f\"- Number of positive specimens for Influenza B: {total_b}\\n\"\n",
    "        user_prompt += f\"- Ratio of positive specimens (%): {pos_rate}\\n\"\n",
    "        user_prompt += f\"- Ratio of positive specimens for Influenza A (%): {a_rate}\\n\"\n",
    "        user_prompt += f\"- Ratio of positive specimens for Influenza B (%): {b_rate}\\n\\n\"\n",
    "        user_prompt += f\"Based on this time-series data, predict whether the percentage of respiratory specimens testing positive for influenza will exceed its average of 6.26% or not in the comming week. \"\n",
    "        user_prompt += \"Respond with either \\'exceed\\' or \\'not exceed\\'. Do not provide any other details.\"\n",
    "        \n",
    "    elif indicator == 'mortality':\n",
    "        user_prompt = f\"Your task is to predict whether the ratio of mortality from Influenza or Pneumonia to the total number of death will:\\n\"\n",
    "        user_prompt += \"(1) Exceed its average of 7.84%\\n(2) Does not exceed its average of 7.84%\\n\"\n",
    "        user_prompt += \"in the coming week. \"\n",
    "        user_prompt += f\"Review the time-series data provided for the last {window_size} weeks. \"\n",
    "        user_prompt += f\"Each time-series consists of weekly values separated by a \\'|\\' token for the following indicators:\\n\"\n",
    "        user_prompt += f\"- Total number of death: {total_death}\\n\"\n",
    "        user_prompt += f\"- Number of death from influenza: {inf_death}\\n\"\n",
    "        user_prompt += f\"- Number of death from pneumonia: {pneum_death}\\n\"\n",
    "        user_prompt += f\"- Ratio of mortality from Influenza or Pneumonia (%): {ratio}\\n\\n\"\n",
    "        user_prompt += f\"Based on this time-series data, predict whether the ratio of mortality from Influenza or Pneumonia to the total number of death will exceed 7.84% or not. \"\n",
    "        user_prompt += \"Respond with either \\'exceed\\' or \\'not exceed\\'. Do not provide any other details.\"\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4-1106-preview\",\n",
    "        messages=[\n",
    "        {\n",
    "          \"role\": \"system\",\n",
    "          \"content\": system_prompt\n",
    "        },\n",
    "        {\n",
    "          \"role\": \"user\",\n",
    "          \"content\": user_prompt\n",
    "        }\n",
    "        ],\n",
    "        temperature=0.7,\n",
    "        max_tokens=2048,\n",
    "        top_p=1\n",
    "    )\n",
    "\n",
    "    text = response.choices[0].message.content\n",
    "\n",
    "    with open(f'gpt_predict_time/{i}_{indicator}.txt', 'w') as f:\n",
    "        f.write(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff89ee4-c07a-414e-a6d8-003d301b8ef5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
